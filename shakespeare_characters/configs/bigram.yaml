device: "cpu"
model:
  arch: "bigram"
  context_length: 8
train:
  batch_size: 32
  eval_interval: 100
  eval_iters: 20
  learning_rate: 1.e-3
  max_iters: 15_000
