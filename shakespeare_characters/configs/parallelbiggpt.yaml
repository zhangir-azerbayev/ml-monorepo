device: "cuda:0"
model:
  arch: "ParallelGPTModel"
  context_length: 32
  d_model: 128
  num_heads: 8
  n_layers: 5
train:
  batch_size: 128
  eval_interval: 100
  eval_iters: 1
  learning_rate: 3.e-4
  max_iters: 20_000
  # train_set_length: 9
wandb:
  name: "parallel_biggpt"
